{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Lesson 1\n",
    "    Worked on in connection with O'Reilly NLP course w.safaribooksonline.com/videos/natural-language-processing\n",
    "    \n",
    "    Below code reproduced manually from here https://github.com/bmtgoncalves/FromScratch/blob/master/NLP/NLP%20Lesson%201.ipynb\n",
    "    with my own additions/subtractions/comments\n",
    "\"\"\"\n",
    "\n",
    "import string\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "text = \"\"\"Mary had a little lamb, little lamb,\n",
    "    little lamb. Mary had a little lamb\n",
    "    whose fleece was white as snow.\n",
    "    And everywhere that Mary went\n",
    "    Mary went, Mary went. Everywhere\n",
    "    that Mary went,\n",
    "    The lamb was sure to go\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize words from the text\n",
    "def extract_words(text):\n",
    "    temp = text.split()\n",
    "    text_words = []\n",
    "    \n",
    "    # Get rid of punctuation and downcase each word\n",
    "    for word in temp:\n",
    "        while word[0] in string.punctuation:\n",
    "            word = word[1:]\n",
    "            \n",
    "        while word[-1] in string.punctuation:\n",
    "            word = word[:-1]\n",
    "        \n",
    "        text_words.append(word.lower())\n",
    "    \n",
    "    return text_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words = extract_words(text)\n",
    "\n",
    "# key: word, value: unique word_id\n",
    "word_dict = {}\n",
    "# list of unique words from text_words\n",
    "word_list = []\n",
    "# list of word_ids in order as words appear in text_words\n",
    "text_tokens = []\n",
    "# counter to generate word_ids\n",
    "word_id = 0\n",
    "\n",
    "\"\"\"\n",
    "    take each tokenized word and 1) add it to the\n",
    "    word_dict and unique word_list if not already\n",
    "    there (i.e., no word repeats) and 2) append \n",
    "    it's word_id to the text_tokens list\n",
    "    (i.e., repeats ok)\n",
    "\"\"\"\n",
    "for word in text_words:\n",
    "    if word not in word_dict:\n",
    "        word_dict[word] = word_id\n",
    "        word_list.append(word)\n",
    "        word_id += 1\n",
    "    \n",
    "    text_tokens.append(word_dict[word])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mary': 0, 'had': 1, 'a': 2, 'little': 3, 'lamb': 4, 'whose': 5, 'fleece': 6, 'was': 7, 'white': 8, 'as': 9, 'snow': 10, 'and': 11, 'everywhere': 12, 'that': 13, 'went': 14, 'the': 15, 'sure': 16, 'to': 17, 'go': 18}\n",
      "[0, 1, 2, 3, 4, 3, 4, 3, 4, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0, 14, 0, 14, 0, 14, 12, 13, 0, 14, 15, 4, 7, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "print(word_dict)\n",
    "\n",
    "# tokenized version of text\n",
    "print(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "    ONE_HOT ENCODING\n",
    "    This isn't super useful. We don't know enough about the words \n",
    "    when we represent them with a single int.\n",
    "    Use one-hot encoding instead. Generate a unique vector for each word,\n",
    "    where 1 appears once at an index in the vector unique to that word.\n",
    "\"\"\"\n",
    "\n",
    "def one_hot(word, word_dict=word_dict):\n",
    "    # generate an np vector of all zeros\n",
    "    vector = np.zeros(len(word_dict))\n",
    "    # flip 0 to 1 at the index where the word's word_id is\n",
    "    vector[word_dict[word]] = 1\n",
    "    return vector\n",
    "\n",
    "# one_hot definitions of 'mary' and 'fleece'\n",
    "print(one_hot('mary'))\n",
    "print(one_hot('fleece'))\n",
    "print(one_hot('mary') + one_hot('fleece'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 2. 2. 4. 5. 1. 1. 2. 1. 1. 1. 1. 2. 2. 4. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "    BAG OF WORDS\n",
    "    One-hot vectorization works ok above because relatively small\n",
    "    dictionary of words. If we were attempting to one-hot vectorize\n",
    "    the entire english language, we'd have a vector space of a million\n",
    "    which wouldn't be efficient. We'd have a vector with lenght a million\n",
    "    or so for each word, and only one value would be flipped to 1. A waste\n",
    "    of zeros, basically.\n",
    "    \n",
    "    Bag of words: Just keep track of words you are using in text. Use a\n",
    "    dictionary with key word and value how many times word appears. You lose\n",
    "    the word order but get rid of all the vector wasted 0s.\n",
    "\"\"\"\n",
    "\n",
    "text_vector = np.zeros(word_id)\n",
    "\n",
    "for word in text_words:\n",
    "    # count no. of times word appears by adding\n",
    "    # 1 to vector position at word_index\n",
    "    text_vector[word_dict[word]] += 1\n",
    "    \n",
    "print(text_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0469fb690a51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 'mary' is at word_index 0. Looks like she appears 6 times.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Confirm: How many times does 'mary' appear?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'text_vector' is not defined"
     ]
    }
   ],
   "source": [
    "# 'mary' is at word_index 0. Looks like she appears 6 times.\n",
    "# Confirm: How many times does 'mary' appear?\n",
    "print(text_vector[word_dict['mary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'mary': 6,\n",
      "         'lamb': 5,\n",
      "         'little': 4,\n",
      "         'went': 4,\n",
      "         'had': 2,\n",
      "         'a': 2,\n",
      "         'was': 2,\n",
      "         'everywhere': 2,\n",
      "         'that': 2,\n",
      "         'whose': 1,\n",
      "         'fleece': 1,\n",
      "         'white': 1,\n",
      "         'as': 1,\n",
      "         'snow': 1,\n",
      "         'and': 1,\n",
      "         'the': 1,\n",
      "         'sure': 1,\n",
      "         'to': 1,\n",
      "         'go': 1})\n"
     ]
    }
   ],
   "source": [
    "# Do the same thin use the python Counter module\n",
    "word_counts = Counter(text_words)\n",
    "pprint(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    STOP WORDS\n",
    "    Words that carry little meaning and can be discarded\n",
    "    \"the\", \"and\", \"a\", etc\n",
    "    Often occur frequently, but not always so can't just throw\n",
    "    words out based on frequency\n",
    "    Usually use manually curated list of words created by linguists\n",
    "\"\"\"\n",
    "\n",
    "# get list of items [(key, value),...] from word_count above and sort by frequency descending\n",
    "items = list(word_counts.items())\n",
    "sorted(items, key=lambda x:x[1], reverse=True)\n",
    "\n",
    "# Not easy to draw conclusions from above small piece of text\n",
    "# import the first 100 MB of the english Wikipedia from: http://mattmahoney.net/dc/textdata\n",
    "\n",
    "data = []\n",
    "\n",
    "for line in gzip.open(\"data/text8.gz\", 'rt'):\n",
    "    data.extend(line.strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1061396\n",
      "of 593677\n",
      "and 416629\n",
      "one 411764\n",
      "in 372201\n",
      "a 325873\n",
      "to 316376\n",
      "zero 264975\n",
      "nine 250430\n",
      "two 192644\n"
     ]
    }
   ],
   "source": [
    "# count and sort the wikipedia data\n",
    "counts = Counter(data)\n",
    "sorted_counts = sorted(list(counts.items()), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "# print the top 10 works. Note that they aren't particularly interesting or useful.\n",
    "for word, count in sorted_counts[:10]:\n",
    "    print(word, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Word frequency distribution')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEaCAYAAAAG87ApAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XecVOXZ//HPtY2VLk2ULiCCqIgr9t5QQYyxoolGo2KixscU8feYxyTGlkSTKBjLo0KiglgeYy+JCliiLAIKKLAiygLSkV52uX5/zFkcli0zuzN7Zs5+36/XvJhzz5lzrpvZnWvvcu5j7o6IiEiicsIOQEREsosSh4iIJEWJQ0REkqLEISIiSVHiEBGRpChxiIhIUpQ4JOOY2W/M7PEaXr/azJaa2Xoza9uQsWUiMxtjZr8Pnh9tZnNSeOxXzeyS4PmlZvZuCo99kZm9karjScNR4pAamdlNZvZqpbJ51ZRd0ADx5AP3AKe4e3N3X5nuc2YTd5/s7n1q26+25Bx3vNPcfWx94zKz7mbmZpYXd+wn3P2U+h5bGp4Sh9RmEnCEmeUCmNmeQD5wUKWyXsG+CbOYZH8G9wAKgVnVHDOvqnJJTh0/G2kk9IMhtZlCLFEMCLaPBt4G5lQq+8LdFwOY2RFmNsXMvg3+PaLiYGb2jpndZmbvARuBvc2sh5lNNLN1ZvYm0K6qQMxsn+C8AGvM7K2g3M3sp2Y2D5gXlO1rZm+a2Sozm2Nm58Udp62ZvWBma83sIzO7taILpqq/jIOYfxy3fZmZfWZmq83sdTPrFveam9mIoAW2xsxGm5nFvX5F8N51ZjbbzAaa2S/N7NlKdb3XzP5azf/DQWb2cXCMp4gl0orXjjOz0rjtG81sUbDvHDM70cwGA/8POD/o7ptRw2ezU91ju9mo4LP93MxOjHthgZmdFLcd36qp+KNiTXDOwyt3fSXwc3Ormb0X1OUNM6vy50TST4lDauTuW4EPgWOComOAycC7lcomAZhZG+Bl4F6gLbFupZdt57GIHwBXAi2Ar4AnganEEsatwCXVxDIX2C/YbO3uJ8S9fBZwKNDPzJoBbwbH7QBcANxvZv2CfUcDm4E9gcuCR0LMbBixL92zgfbB/8W4SrsNAQ4BDgDOA04N3nsu8Bvgh0BL4ExgJfA4MNjMWgf75QUx/72K8xcAzwP/ANoATwPfrybWPsA1wCHu3iKIY4G7vwbcDjwVdPcdGPe2yp9NZYcCXxD7rG4Bngs+89pU/Ky0Ds75QaVYE/m5GQ78iNhnWgD8IoHzShoocUgiJvLdL/7RxL4sJ1cqmxg8PwOY5+7/cPcydx8HfA4MjTveGHef5e5lxL68DwF+7e5b3H0S8GIdYrzD3Ve5+yZiX9wL3P2xIIZpwLPAuUH32veB/3H3De4+E0imD39EcK7PgvhvBwbEtzqAO919jbt/Tax1VtEy+zHwB3ef4jEl7v6Vuy8hlnjPDfYbDKxw96lVnP8wYi3Av7j7Nnd/hlirsCrlQBNiyTTf3Re4+xe11G/HZ+Pu26p4fVncuZ8i1gI8o5ZjJiKRn5vH3H1u8BlP4Lv/V2lgShySiEnAUcFfhe3dfR7wPrGxjzZAf77ritiLXf9S/QroFLe9MO75XsBqd99Qaf9kxR+zG3Bo0FW0xszWABcBHYm1EvIq7Z/M+boBf4077irA2Ll+38Q93wg0D553IfbXelXGAhcHzy8m1qKoyl7AIt95ddIq43f3EuB6Yq2cZWY23sz2qua4FRbW8npV567tmIlI5Oemuv9XaWBKHJKID4BWwBXAewDuvhZYHJQtdvcvg30XE/tyjdcVWBS3Hf/FswTYPeheit8/WfHHXAhMdPfWcY/m7n41sBwoI/YlXtX5KhJY07iyjpWOfVWlY+/m7u8nEONCoGc1rz0PHGBm/Ym1mJ6oZr8lQKf4cRNq+P9y9yfd/Shin4kDd1W8VN1bqjtWoKpzLw6eb6D6/7fajpvIz41kCCUOqVXQNVAM3ECsi6rCu0FZ/GyqV4B9zGy4meWZ2flAP+Clao79VXDs35pZgZkdxc7dE3XxUhDDD8wsP3gcYmZ93b0ceA74jZk1DcY9doypuPtyYl9WF5tZrpldxs5f9g8AN5nZfgBm1ioYu0jE/wK/MLODLaZXRReXu28GniE2LvNR0M1VlQ+IJb7rgnqdDQyqakcz62NmJ5hZE2JjOpuA7cHLS4HulvzMqQ5x5z4X6EvsMweYDlwQvFYEnBP3vuXBufeu5rhJ/dxIuJQ4JFETiX1pxF8ANjko25E4gusqhgA/Jzbw+ytgiLuvqOHYw4kNuq4iNuC6y6BwMtx9HXAKsQHmxcS6OO4i1t8PsQHj5kH5GOCxSoe4AvhlEP9+xLrlKo79f8GxxpvZWmAmcFqCcT0N3EYsOawj1sqIH1geC+xP9d1UFZMVzgYuJfb/dT6xRFiVJsCdwApide0A3BS89nTw70oz+ziR+AMfAr2DY94GnBN3Lc2viSXZ1cBvidWzIu6Nwf7vBd18h1WqV11+biQkphs5SWNnZpcCPw66dMKMoyuxAeGOQVegSEZSi0MkAwRdRjcA45U0JNPpKluRkAUTA5YSm0U0OORwRGqlrioREUmKuqpERCQpShwiIpKUrBjjMLOziC1J0BJ4xN1rXMO/Xbt23r1794YITUQkMqZOnbrC3dvXtl/aE4eZPUpsfvYyd+8fVz4Y+CuQC/yvu99Z3THc/XngeTPbHfgTUGPi6N69O8XFxakIX0Sk0TCzhJbfaYgWxxhgFHEXdQULzY0GTgZKgSlm9gKxJHJHpfdf5u7Lguc3B+8TEZGQpD1xuPskM+teqXgQUOLu8wHMbDwwzN3vINY62UmwNs6dwKvuXuVVrmZ2JbHloOnatS5LHYmISCLCGhzvxM6rcJay8yqYlV0LnAScY2YjqtrB3R9y9yJ3L2rfvtYuOhERqaOsGBx393uJ3eClRmY2FBjaq1ev9AclItJIhdXiWMTOy1p3JgXLJ7v7i+5+ZatWrep7KBERqUZYiWMK0Nti95ouILaK6Qv1PaiZDTWzh7799tt6BygiIlVLe+Iws3HE7iHQx8xKzezy4Jab1wCvA58BE9x9Vn3PVd8Wx5JvN/HOnGW17ygi0og1xKyqC6spf4XvbgCTEvUd4/jNC7OYPG8FL157FD3b666UIiJVidSSI/Vtcfz2zP40ycvhp098zOZt5SmOTkQkGiKVOOqrY6tC7j7vQD7/Zh2/f3l22OGIiGSkSCWOVAyOn7DvHlx5zN48/p+vefmTJSmMTkQkGiKVOFI1HfcXp/RhQJfWjHz2E75euTFF0YmIREOkEkeqFOTlcN+FB4HBNeM+ZmvZ9rBDEhHJGJFKHKm8jqNLm6b88ZwD+KT0W+567fMURCciEg2RShypvnJ8cP89ueTwbjzy7pe8OXtpSo4pIpLtIpU40uGm0/uy314t+cXTM1i0ZlPY4YiIhE6JoxaF+bmMGj6QsvLtXDduGtvKNd4hIo1bpBJHutaq6tGuGbefvT9Tv1rNn9+cm9Jji4hkm0gljnSujjtsQCcuOKQL97/zBRPnLk/58UVEskWkEke63TJ0P/bZozk3PDWdZWs3hx2OiEgolDiSsFtBLqOHD2TD1jJ+Nn465ds97JBERBqcEkeSeu/Rgt8N688H81cy6q2SsMMREWlwkUocDXUjp3MP7sz3DurEX/89lw++WJnWc4mIZJpIJY6GunWsmXHrWf3p3rYZPxs/jZXrt6T1fCIimSRSiaMhNW+Sx33DD2LNpm3cMGEG2zXeISKNhBJHPey3Vyt+fUZfJs5dzkOT54cdjohIg1DiqKeLD+vGaf078sfX5zD1q9VhhyMiknZKHPVkZtz5/QPYs1Uh142bxuoNW8MOSUQkrZQ4UqDVbvmMHj6QZes2818Tpmu8Q0QiLVKJo6Gm41blwC6t+Z8h/XhnznJGva3rO0QkuiKVOBpqOm51Lj6sG2cN2Is//2suk+dpPSsRiaZIJY6wmRm3n70/vTs052fjp7NY9+8QkQhS4kixpgV5/O3ig9myrZyfPKH7lYtI9ChxpEHP9s3547kHMn3hGm5/5bOwwxERSSkljjQ5ff89ufyoHox5fwEvzFgcdjgiIimjxJFGI0/bl6JuuzPy2U+Yt3Rd2OGIiKSEEkca5efmMGr4QJoW5HL1Ex+zYUtZ2CGJiNRbxicOM+trZg+Y2TNmdnXY8SSrY6tC7r3gIOYvX8/I5z7FXRcHikh2S2viMLNHzWyZmc2sVD7YzOaYWYmZjazpGO7+mbuPAM4DjkxnvOlyRK92/PyUPrw4YzFj318QdjgiIvWS7hbHGGBwfIGZ5QKjgdOAfsCFZtbPzPY3s5cqPToE7zkTeBl4Jc3xps3Vx/bkpL4duO2Vz/j4ay2GKCLZK62Jw90nAasqFQ8CStx9vrtvBcYDw9z9U3cfUumxLDjOC+5+GnBRdecysyvNrNjMipcvz7yrtnNyjLvPHUDHVoX89ImPdfMnEclaYYxxdAIWxm2XBmVVMrPjzOxeM3uQGloc7v6Quxe5e1H79u1TF20KtWqaz98uOpiVG7bys/HTKddiiCKShTJ+cNzd33H369z9KncfXdO+YS5ymKj+nVpx67D9eLdkBX/919ywwxERSVoYiWMR0CVuu3NQVm9hL3KYqPMP6cp5RZ25960S3v58WdjhiIgkJYzEMQXobWY9zKwAuAB4IRUHzoYWR4XfDetPvz1bcv1T01m4amPY4YiIJCzd03HHAR8Afcys1Mwud/cy4BrgdeAzYIK7z0rF+bKlxQFQmJ/L3y4eyHZ3fvLEx2zeVh52SCIiCbEoXZBmZkOBob169bpi3rx5YYeTkDdmfcOV/5jK8EO7cvv39g87HBFpxMxsqrsX1bZfxg+OJyObWhwVTtmvIyOO7cmTH37NM1NLww5HRKRWkUoc2eoXp+zDkb3a8v/+71M+Lc388RkRadwilTiyaXA8Xl5uDvddOJD2zZtw1T+KdXGgiGS0SCWObOyqqtCmWQEP/iB2ceBPn/yYsnLdOVBEMlOkEke269+pFXecvT//mb+KO1/9POxwRESqFKnEka1dVfHOHtiZS4/ozv+++yX/nJ6S6yJFRFIqUokjm7uq4v33GX0Z1L0NNz77CXO+0Z0DRSSzRCpxREV+bg6jLjqI5k3yuHacLg4UkcyixJGhOrQo5J7zBjB36XpufWl22OGIiOwQqcQRhTGOeMfs056rjtmbJz78mtdmLgk7HBERIGKJIypjHPF+fkofDuzcil898wmL1mwKOxwRkWgljigqyMvh3gsPYrvD9eOn6foOEQmdEkcW6Na2Gbd9rz9TFqzm5udnEqWFKUUk++SFHYAkZtiATpQsW899b5WwV+vduO7E3mGHJCKNVKQSR9yy6mGHkhY3nLwPi9Zs4p4357Jnq0LOLepS+5tERFIsUl1VURwcj2dm3Hn2ARzdux03PfcpE+cuDzskEWmEIpU4GoOCvBzuv2ggvfdowU8en8rMRdGYeiwi2UOJIwu1KMxnzI8OoXXTAn40ZoruWS4iDUqJI0vt0bKQMT86hC3byrn0sY9Ys3Fr2CGJSCOhxJHFeu/Rgod/WMTCVZu4bvx0tm/XNF0RST8ljix36N5tueXMfkyau5z73ykJOxwRaQQilTiitlZVooYP6sqZB+7FPW/O5YMvVoYdjohEXKQSR9Sn41bHzLj97P3p3rYZ142fxjffbg47JBGJsEgljsaseZM8/nbxwWzcUsblY6ewcWtZ2CGJSEQpcURIn44tGDV8IJ8tWcv1GiwXkTRR4oiY4/ftwK+H9OON2Uu567XPww5HRCIoUmtVScylR3Rn/vINPDhpPj3aNeOCQV3DDklEIkSJI4LMjFuG9uOrVRu5+fmZdGvbjMN7tg07LBGJCHVVRVRebg6jhh9Et7ZNuW78NJav2xJ2SCISEVmROMysmZkVm9mQsGPJJi0L8xk1fCBrN23jhgkaLBeR1Ehr4jCzR81smZnNrFQ+2MzmmFmJmY1M4FA3AhPSE2W09d2zJbcM3Y/J81bwwKQvwg5HRCIg3WMcY4BRwN8rCswsFxgNnAyUAlPM7AUgF7ij0vsvAw4EZgOFaY41si4c1IX3vljB3W/MZVD3NhR1bxN2SCKSxdLa4nD3ScCqSsWDgBJ3n+/uW4HxwDB3/9Tdh1R6LAOOAw4DhgNXmFmVMZvZlUF3VvHy5brBUTwz446z96dT6924dtw0vlq5IeyQRCSLhTHG0QlYGLddGpRVyd3/292vB54EHnb37dXs95C7F7l7Ufv27VMacBS0LMzn/osGsmlbOWeOeo/3v1gRdkgikqWyYnAcwN3HuPtLNe3TWBc5TFT/Tq3450+PpEOLJlw+pphPS/X/JCLJCyNxLAK6xG13DsrqrbEucpiMbm2b8cQVh9KmWQGXjZ3CsnVaEFFEkhNG4pgC9DazHmZWAFwAvJCKA6vFkZgOLQp59NJDWLVhK49M/jLscEQky6R7Ou444AOgj5mVmtnl7l4GXAO8DnwGTHD3Wak4n1ocievTsQWn778nT374Nes2bws7HBHJIuYenYvCzGwoMLRXr15XzJs3L+xwMt4npWs4c9R79O/Ukj1aFHL/xQNpkpcbdlgiEhIzm+ruRbXtlzWD44lQiyM5B3RuzRkH7MnqDdv49+fLeHZqSoaaRCTiIpU4JHmjhw/k3RuP58Aurbn/nRK2lVc521lEZIekE0ewblRG9mdocLxuzIzrT+xN6epN3PjMJ8xYuIYtZeVhhyUiGarWMY7gSu0LgIuAQ4AtQBNgBfAy8KC7l6Q5zqQUFRV5cXFx2GFkFXfnvrdKuOfNuQAc1LU14688TGMeIo1IKsc43gZ6AjcBHd29i7t3AI4C/gPcZWYX1ytaCZ2Zcd2JvZlw1eH89+l9mfb1Gv70+pywwxKRDJTIIocnufsu8zXdfRXwLPCsmeWnPLI6iJtVFXYoWWtQjzYM6tGGmYu/ZfxHC7nh5D7sVqBWh4h8p9YWR0XSMLN/VH6toqyqxBIGzapKnQsO6cq6LWX87qXZzFqsMSMR+U4yg+P7xW8EA+QHpzYcyRSH7d2Gnu2bMe6jrxnx+FS2lmm2lYjE1Jo4zOwmM1sHHGBma4PHOmAZ8M+0RyihMDOeHnEEfz7/QBau2sSTH34VdkgikiES6aq6w91bAH9095bBo4W7t3X3mxogxoRpOm5qtWlWwFkDOnFEz7bc+1aJliYRESCJrip3v8nMOpnZEWZ2TMUjncElS2McqWdm3Dh4X1Zt2Mrp905myoLK9+USkcYm4cRhZncC7wE3A78MHr9IU1ySQQ7s0poHf3AweTk5XPLoR/xz+iLKdIW5SKOVzD3Hvwf0cfct6QpGMtep+3XkoC6tueIfU/nZ+Om8OXspo4YPDDssEQlBMrOq5gMZcb2GhKNDy0KeGXE4wwbsxaszv2Hlev0NIdIYJZM4NgLTzexBM7u34pGuwOpCg+Ppl5+bw1XH9KR8uzN+ysLa3yAikZNMV9ULpOhOfeni7i8CLxYVFV0RdixR1nfPFpzUdw/ufmMOu+Xnst2dHxzeTetaiTQSCScOdx+bzkAke5gZf71gACMen8rvXpoNQLvmTTjroE4hRyYiDSGZWVVfmtn8yo90BieZq1mTPP58/oAd28VfaZquSGORzBhHEbFl1Q8BjgbuBR5PR1CSHdo1b8LUm0/i6N7teGPWUmYu0tiSSGOQzAWAK+Mei9z9L8AZaYxNskDb5k24/qR9WLZuC8NGv8fCVRvDDklE0iyZrqqBcY8iMxtBcoPraadZVeE4uNvuTLjqcMq3O49rTSuRyEvmi//uuOdlwALgvJRGU0+aVRWeQT3acFr/jjw4cT5H9GzHsfu0DzskEUmTZGZVHZ/OQCT7/fn8AcxeMonbXp7NkT2PJi836Vvai0gWSKarqpWZ3WNmxcHjbjPTaoKyQ2F+LiMH78vcpesZ8fjHDH/4P7w285uwwxKRFEvmT8JHgXXEuqfOA9YCj6UjKMleg/t3pO+eLfnXZ0t5/4uVjHh8KsvXaWkSkShJJnH0dPdb3H1+8PgtsHe6ApPsZGbcf9FA7j73wB1lx//pHYq1HLtIZCSTODaZ2VEVG2Z2JLAp9SFJtuvRrhnfP7gzn986GID1W8o454EPNFVXJCKSSRxXA6PNbIGZLQBGASPSEpVEQmF+Lnu3a7Zj+7+ems64j74OMSIRSQVz9+TeYNYSwN3XpiWiFCgqKvLi4uKwwxBg3eZtTJy7nGuenAZAfq4x77bTQ45KRKpiZlPdvai2/ZKZVXW7mbV297XuvtbMdjez39cvzITOe5yZTTazB8zsuHSfT1KrRWE+p/ffc8f2tnLn3XkrWLZuc4hRiUh9JNNVdZq7r6nYcPfVQI1/OprZo2a2zMxmViofbGZzzKzEzEbWcl4H1gOFQGkS8UqGyMkxnv/pkdwytB8AFz/yISf+aWLIUYlIXSWTOHLNrEnFhpntBjSpYX+AMcDg+AIzywVGA6cB/YALzayfme1vZi9VenQAJrv7acCNwG+TiFcyyIAurbno0G5cOKgrAOu2lDFhykKS7SoVkfAls+TIE8C/zazi2o0fATXeo8PdJ5lZ90rFg4ASd58PYGbjgWHufgcwpIbDraaGRGVmVwJXAnTt2rWmsCQkBXk53HH2/sxYuIbZS9byq2c/oUf7ZhzSvU3YoYlIEpJZcuQuM5sBnBQU3erur9fhnJ2A+HuOlgKHVrezmZ0NnAq0JjaTq7r4HgIegtjgeB3ikgZy5oC9mL0kNrfi3Ac+oFlBLg9fUsQRPduFHJmIJKLWxGFm5kF/gru/BrxW0z6p5u7PAc8lsq+ZDQWG9urVKx2hSIr8+Kge3Pnq5zu2N2wtZ/TbJeyzRwvaNa+t91NEwpbIGMfbZnatme3U/2NmBWZ2gpmNBS5J4pyLgC5x252Dsnpz9xfd/cpWrbSEViaravHD90pWUvT7f4UQjYgkK5HEMRgoB8aZ2RIzm21mXwLzgAuBv7j7mCTOOQXobWY9zKwAuAB4Icm4q6T7cWS/rWXbww5BRGqR1AWAZpYPtAM2xU/NrWH/ccBxwXuWAre4+yNmdjrwFyAXeNTdb6tD7NXSBYCZ79uN23CcwvxcfvjIR3wUrGV18xl9GTagE+1bqMtKpKElegFgrYnDzAqJLS3SC/iE2Bd9WUqiTLG4MY4r5s2bF3Y4kqAXZyzm2nHTdiqb9uuT2b1ZQUgRiTROqbxyfCxQBHxK7IK/u2vePTwa48hO++3Vcpeyq5+YGkIkIpKIRKbj9nP3/QHM7BHgo/SGJI3NHi0Ldyn7z/xVLFy1kS5tmoYQkYjUJJEWx7aKJ5naRVVBg+PZqVmT2N8vTQtydyo/9S+TWLt5G9vKNWAukkkSGeMoBzZUbAK7ARuD5+7uu/YzhEyD49nnoy9X0Wn33Zi3dB2XPjZll9cX3HlGCFGJNC4pG+Nw91x3bxk8Wrh7XtzzjEsakp0G9WhDp9a7cVyfDhzZqy2F+Tv/aHYf+TK/fXFWSNGJSLxkFjnMeOqqioYnfnwY153Ye5fyx95b0PDBiMguIpU4NKsqOrpWMyg+ce7yBo5ERCqLVOKQ6Dhs77ZVll/y6Ed0H/kyMxepVSkSFiUOyUjtmjfhqSsPq/b1Ife9y9yl6xowIhGpEKnEoTGOaOnerlmNry9ctbGBIhGReJFKHBrjiJbdKl3XUdnlY4u5799aWkakoUUqcUi0tCzM5183HMNzPzkCgJ+fvM8u+9z95lzKdIGgSINS4pCM1qtDCwZ23Z0Fd57BAV1aV7nPQb97k/LtuumjSENR4pCssa2ae3Ws21LGDROmN3A0Io1Xwvcczwa6dWy0tavhHh3/nL6YloX5LF+3hZP77cH3D+7cgJGJNC5J3cgpW2itqugqXrCKcx74oNb9tLaVSPJSeT8OkYxR1L0ND/7gYM4r6szh1VwkCLFFE0UkPZQ4JOucul9H/nDOgZywb4dq9znvwVirZEtZORu3ZvTdAESyjhKHZK3LjupR6z5n3vce/f7n9QaIRqTxUOKQrJWbYzW+/vInS5gTtyzJs1NLGf12SbrDEom8SCUOLTnS+Hz865OZ+dtTaZK364/yT5/8eKftnz89gz++PqehQhOJrEglDi050vi0aVZA8yZ5/OX8ATXut7Waa0BEJHmRShzSeJ3Qt/qBcoDhD/+ngSIRiT4lDomEJnk1L4hY/NXqHc+nLFi1y0yrk+6ZyJV/17U/IolQ4pBG59wHPuCGp2bsVFaybD1vzF4aUkQi2UWJQxqlmYs1gUKkrpQ4JDIm/+p4LhzUNaF9twer6U79ajVj31+QxqhEokdrVUnkbN/uTC5ZwSWPfpT0e7XGlTRmWqtKGq2cHOPYfdqHHYZIZGV84jCzHDO7zczuM7NLwo5HssdVx+4ddggikZTWxGFmj5rZMjObWal8sJnNMbMSMxtZy2GGAZ2BbUBpumKV6OnapmnS77n9lc90K1qRWqS7xTEGGBxfYGa5wGjgNKAfcKGZ9TOz/c3spUqPDkAf4H13vwG4Os3xSoTk5yb/4/3QpPkc/Ye32bytPA0RiURDWhOHu08CKt8YYRBQ4u7z3X0rMB4Y5u6fuvuQSo9lxFoZFVdvVfvbbGZXmlmxmRUvX748HdWRLHNcHcc5lny7mb/8a16KoxGJjjDGODoBC+O2S4Oy6jwHnGpm9wGTqtvJ3R9y9yJ3L2rfXgOjAh1aFjJ6+MA6vfe1mUtSHI1IdGT84Li7b3T3y939WncfXdO+Wh1XKjvjgD3r9L4FKzfy/hcrAFi2bjNrNm5NZVgiWS2MxLEI6BK33TkoqzetjitVGVLH5DH84Q955dMlDLrt3wz43Zspjkoke6X9AkAz6w685O79g+08YC5wIrGEMQUY7u6zUnCuocDQXr16XTFvnvqoJWZb+XbWbS6jbPt2Bt3273of7+Nfn0ybZgUpiEwks2TEBYBmNg74AOhjZqVmdrm7lwHXAK8DnwETUpE0QC0OqVp+bg5tmhXQoUUhFx+W2JIkNflyxfqdtke/XULJsnXV7C0SPemeVXWhu+/p7vnu3tndHwnKX3G47nA4AAAL7ElEQVT3fdy9p7vflqrzaYxDanNwt91Tdqz1W8pYvWErf3x9Duc88EHKjiuS6fLCDiCV3P1F4MWioqIrwo5FMlOO1Xyf8kRU9O72v+V1mhXE7gOyZZsuGpTGI+NnVYmkUkoSB7BqQ2yW1YatulBQGp9IJQ51VUltcnNS0+K4YcL0ncpSkI9EskakEocGx6U2eSlIHM9OLd3R4hBpjCKVOERqc8K+HfjxUT349ZB+dT7GU8UL2V5pGrsaHNKYRGpwPO46jrBDkQyVl5vDzUP68fy0+l1zOnPR2p22N2wt56i73mL3pgXMWvwt//eTIzmwS2sA7nljDm2aFTBr8VpO7LsHg/t3rNe5RcIWqRaHuqokTKWrN/Hpom/Z7vDLZ2bsKL/3rRJ+8+Jsnp5ayojHp4YYoUhqRKrFIVIf7Vs0Yfm6LSk51naHO175jO7tmqXkeCKZRIlDGqUjerYF4Kpj9ubBSfM5Zp/25Bi8Myc1S/KvWL+FByfNT8mxRDJNpBKHxjgkUR1aFrLgzjMAuOn0vgBcN25ayo5fVp7eNeBEwqQxDpFAKq/FWL+lrNrXZi7SdUaS3SKVOETqo6Gm1E4oXlj7TiIZTIlDJGC6/FskIUocIoGmwYKF6TaheCHdR77MVys3MGPhGk7580Q21NC1JZJpIpU4tFaV1MfI0/alRWH654tsDlbSHfVWCXe8+hlzl65nRumatJ9XJFUilTg0OC710aIwn09/cyoL7jyDffZoHnY4IhkrUolDJFXSfEdlkaymxCFShT4dW6T9HE9PLeU/81cBMPzhD9lStvO9PQbe+iYn3TMx7XGIJEuJQ6QKfzjnAEaeti97tipssHNu3LJz4li1YSsly9ZXs7dIeJQ4RKrQtCCPEcf25IObTmywc6p3TLJFpBKHZlWJiKRfpBKHZlVJNpv29WrmfLOOhas24nGj81vLtjP1q1UsXbuZdZu3JXSsleu3sK18e7pClUYuUoscimSzy8cW73g+4tieO56fNfo9Zi/57sZRFYszVqesfDsH//5fnDVgL/5ywUGpD1QavUi1OETSqUleDu/eeHyDnOuZqaU7nscnjUSUB62Vlz9dktKYRCoocYgkyB067960oc5W53fmBGtu6VoUSRclDpEMVJ8v/YqlGrcrc0iaKHGIJMgbcMJsKs6ktCHposQhkqCG/APeU3AyNTgkXTSrSiRBDfk9vHpj9dNurx8/jf/MX8Xe7ZuRY0arpvm0b96EY/Zpx6xFa9lS9t003Dtf/ZzT+nfk203bKMzPpUOLJphBt7bNdjnux1+vZv9OrcjP1d+TUrOMTxxmdjRwEbFY+7n7ESGHJI1UKloBqfD89MUAfLN2807lY95fsMu+D0z8ggcmfrFLeeUpvXOXruPs+9/nR0d255ah+6UuWImktP5pYWaPmtkyM5tZqXywmc0xsxIzG1nTMdx9sruPAF4CxqYzXpGqzLjlFOC7Fse8207jhH07hBdQGqzesBWAWYuSm/orjVO6WxxjgFHA3ysKzCwXGA2cDJQCU8zsBSAXuKPS+y9z92XB8+HA5WmOV2QXTfJ2/vsqPzeHPVo23OKHDSEnJzYXqzxDWlWS2dKaONx9kpl1r1Q8CChx9/kAZjYeGObudwBDqjqOmXUFvnX3ddWdy8yuBK4E6Nq1a/2DFwlU3Ip85+/UaH3BVlz7oSm8kogwRsE6AQvjtkuDsppcDjxW0w7u/pC7F7l7Ufv27esZosh3bMeVEd+J2vdr0OBg+/aIVUzSIuMHxwHc/ZZE9jOzocDQXr16pTkiaUxs17wRucSRq64qSUIYLY5FQJe47c5BWb1pdVxJhyryRuRUdFVpQV1JRBiJYwrQ28x6mFkBcAHwQioOrPtxSDrkVNHkaMiryBtCRYsjU6YcS2ZL93TcccAHQB8zKzWzy929DLgGeB34DJjg7rNScT61OCQdquqqipqKOpZrjEMSkO5ZVRdWU/4K8Eqqz6cxDkkHq6rFEbHv14r6aIxDEhGptQXU4hCpm4ppuMobkoismFUlkmmy/fv1hqem77S9ZlNsbawvV2zY5TXJLj85vhe9OjRP6zkilTjUVSXpcmiPNvzw8O47tkcc25P3SlZQvt1p3TSfuUvX818n7cOf/zU3vCCTMOWrVXV6TTLf+i1laT+HRXEWRVFRkRcXF9e+o4iI7GBmU929qLb9IjXGISIi6RepxKHrOERE0i9SiUOzqkRE0i9SiUNERNJPiUNERJISqcShMQ4RkfSLVOLQGIeISPpFKnGIiEj6RfICQDP7FpgXV9QK+DbB5+2AFXU8dfzx6rJP5deS2a54Hl8WVl2qKk8k9uqe6zOpPc7a9tFnsvNzfSZVn7ebu9d+C1V3j9wDeKi67dqeA8WpOm+y+9QUd6L1qlQWSl2qKtdnos9En0l2fybxj6h2Vb1Yw3Yiz1N13mT3qSnu2rZfrGafuqpPXaoq12dSf/pMqn5Nn0n9JXWMSHZV1YeZFXsCa7Vkg6jUJSr1gOjUJSr1gOjUpSHrEdUWR308FHYAKRSVukSlHhCdukSlHhCdujRYPdTiEBGRpKjFISIiSVHiEBGRpChxiIhIUpQ4amFmzcxsrJk9bGYXhR1PXZnZ3mb2iJk9E3Ys9WVmZwWfx1NmdkrY8dSVmfU1swfM7BkzuzrseOor+F0pNrMhYcdSV2Z2nJlNDj6X48KOpz7MLMfMbjOz+8zsklQeu1EmDjN71MyWmdnMSuWDzWyOmZWY2cig+GzgGXe/AjizwYOtQTL1cPf57n55OJHWLsm6PB98HiOA88OItzpJ1uMzdx8BnAccGUa8NUny9wTgRmBCw0ZZuyTr4cB6oBAobehYa5NkXYYBnYFtpLoudb3SMJsfwDHAQGBmXFku8AWwN1AAzAD6ATcBA4J9ngw79rrWI+71Z8KOO4V1uRsYGHbs9akHsT9GXgWGhx17feoCnAxcAFwKDAk79nrUIyd4fQ/gibBjr2ddRgJXBfuk9Pe+UbY43H0SsKpS8SCgxGN/mW8FxhPL2KXEsjZkWAstyXpktGTqYjF3Aa+6+8cNHWtNkv1M3P0Fdz8NyLhu0CTrchxwGDAcuMLMMuZ3JZl6uPv24PXVQJMGDDMhdfjuWh3sU57KOPJSebAs1wlYGLddChwK3AuMMrMzSN0yBelUZT3MrC1wG3CQmd3k7neEEl1yqvtMrgVOAlqZWS93fyCM4JJQ3WdyHLGu0CbAKyHEVRdV1sXdrwEws0uBFXFfwJmqus/kbOBUoDUwKozA6qC635O/AveZ2dHApFSeUImjFu6+AfhR2HHUl7uvJDYmkPXc/V5iCT2rufs7wDshh5FS7j4m7Bjqw92fA54LO45UcPeNQFrGNTOmOZkBFgFd4rY7B2XZJir1gOjUJSr1gOjUJSr1gBDqosTxnSlAbzPrYWYFxAb6Xgg5prqISj0gOnWJSj0gOnWJSj0gjLqEPUsgpJkJ44AlfDdN7fKg/HRgLrEZCv8ddpyNpR5RqktU6hGlukSlHplUFy1yKCIiSVFXlYiIJEWJQ0REkqLEISIiSVHiEBGRpChxiIhIUpQ4REQkKUocIhnKzK43s6ZhxyFSma7jEMlQZrYAKHL3FWHHIhJPLQ6RejCzH5rZJ2Y2w8z+YWbdzeytoOzfZtY12G+MmZ0T9771wb/Hmdk7wV0APzezJ4Jl468D9gLeNrO3w6mdSNW0Oq5IHZnZfsDNwBHuvsLM2gBjgbHuPtbMLiO2iu9ZtRzqIGA/YDHwHnCku99rZjcAx6vFIZlGLQ6RujsBeLrii93dVwGHA08Gr/8DOCqB43zk7qUeu4fFdKB7GmIVSRklDpGGUUbw+xbcHa8g7rUtcc/LUU+AZDglDpG6ews4N7i7IkFX1fvElrWG2O1gJwfPFwAHB8/PBPITOP46oEWqghVJFf1lI1JH7j7LzG4DJppZOTCN2G1tHzOzXwLL+e7ukQ8D/zSzGcBrwIYETvEQ8JqZLXb341NfA5G60XRcERFJirqqREQkKUocIiKSFCUOERFJihKHiIgkRYlDRESSosQhIiJJUeIQEZGkKHGIiEhS/j9BV+rgnuVe6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot word frequency distribution\n",
    "# Note that a lot of words are used infrequently (upper left)\n",
    "# and a fiew words are used very frequency (lower right)\n",
    "# and everything else clumps in the middle\n",
    "dist = Counter(counts.values())\n",
    "dist = list(dist.items())\n",
    "dist.sort(key=lambda x:x[0])\n",
    "dist = np.array(dist)\n",
    "\n",
    "norm = np.dot(dist.T[0], dist.T[1])\n",
    "\n",
    "plt.loglog(dist.T[0], dist.T[1]/norm)\n",
    "plt.xlabel(\"count\")\n",
    "plt.ylabel(\"P(count)\")\n",
    "plt.title(\"Word frequency distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 17005207\n",
      "Clean size: 9006229\n",
      "Reduction %: 47.0384041782026\n"
     ]
    }
   ],
   "source": [
    "# Let's trying setting the top 100 most frequently used words\n",
    "# as stop words and removing them. In real life we would use\n",
    "# a curated list of words, but this will do for the example.\n",
    "\n",
    "stopwords = set([word for word, count in sorted_counts[:100]])\n",
    "clean_data = []\n",
    "\n",
    "for word in data:\n",
    "    if word not in stopwords:\n",
    "        clean_data.append(word)\n",
    "\n",
    "# we get rid of a lot of words--almost half\n",
    "print(\"Original size:\", len(data))\n",
    "print(\"Clean size:\", len(clean_data))\n",
    "print(\"Reduction %:\", (1-len(clean_data)/len(data)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mary', 'had', 'a', 'little', 'lamb', 'little', 'lamb', 'little', 'lamb'], ['mary', 'had', 'a', 'little', 'lamb', 'whose', 'fleece', 'was', 'white', 'as', 'snow'], ['and', 'everywhere', 'that', 'mary', 'went', 'mary', 'went', 'mary', 'went'], ['everywhere', 'that', 'mary', 'went', 'the', 'lamb', 'was', 'sure', 'to', 'go']]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    TF/IDF\n",
    "    \n",
    "    TF: Term Frequency (number of times word appears).\n",
    "        After removal of stop words (not meaningufl),\n",
    "        TF is a good indicator of what words are\n",
    "        important/meaningful in a document\n",
    "    IDF: Inverse Document Frequency (how unusual it is for a document\n",
    "        to contain a certain word). This let's you compare a word ACROSS\n",
    "        documents, the idea being the more often a word appears across\n",
    "        documents, the less meaningful it is to a specific document\n",
    "    \n",
    "    TF and IDF are sort of inverses. In TF, the most frequent word is most\n",
    "    meaningful to a doc. In IDF, the least frequent word is most \n",
    "    meaningful to a doc b/c it let's you distinguist it from other docs.\n",
    "    \n",
    "    TF and IDF each have different ways you can calculate them mathematically,\n",
    "    but not matter which you use TF-IDF is TF * IDF. High TF = important to \n",
    "    specific doc, and HIGH IDF (aka LOW DF) equals uncommon in entire corpus of docs.\n",
    "    \n",
    "    TF-IDF gives you a balance of term frequency and inverse doc frequency.\n",
    "    \n",
    "    One way to find stop words would be to look for words with high TF and low IDF.\n",
    "\"\"\"\n",
    "\n",
    "# start with our nursery rhyme again. Split it into four sentences.\n",
    "# Pretend each sentence is its own document.\n",
    "corpus_text = text.split('.')\n",
    "corpus_words = []\n",
    "\n",
    "for document in corpus_text:\n",
    "    doc_words = extract_words(document)\n",
    "    corpus_words.append(doc_words)\n",
    "    \n",
    "print(corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 2,\n",
      " 'and': 1,\n",
      " 'as': 1,\n",
      " 'everywhere': 2,\n",
      " 'fleece': 1,\n",
      " 'go': 1,\n",
      " 'had': 2,\n",
      " 'lamb': 3,\n",
      " 'little': 2,\n",
      " 'mary': 4,\n",
      " 'snow': 1,\n",
      " 'sure': 1,\n",
      " 'that': 2,\n",
      " 'the': 1,\n",
      " 'to': 1,\n",
      " 'was': 2,\n",
      " 'went': 2,\n",
      " 'white': 1,\n",
      " 'whose': 1}\n"
     ]
    }
   ],
   "source": [
    "# calculate the number of documents in which each word appears\n",
    "document_count = {}\n",
    "\n",
    "for document in corpus_words:\n",
    "    word_set = set(document)\n",
    "    \n",
    "    for word in word_set:\n",
    "        document_count[word] = document_count.get(word, 0) + 1\n",
    "\n",
    "pprint(document_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# 'mary' appears in all 4 documents. So, it's pretty useless to use to\n",
    "# distinguish between the documents.\n",
    "pprint(document_count['mary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# 'go' appears in just 1 document, that's good!\n",
    "pprint(document_count['go'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate IDF\n",
    "# as an aside, I don't know why this guy keeps\n",
    "# passing these globals in as arguments, going to make\n",
    "# them defaults\n",
    "def inv_doc_freq(corpus_words=corpus_words):\n",
    "    number_docs = len(corpus_words)\n",
    "    document_count = {}\n",
    "    \n",
    "    for document in corpus_words:\n",
    "        word_set = set(document)\n",
    "        \n",
    "        for word in word_set:\n",
    "            document_count[word] = document_count.get(word, 0) + 1\n",
    "    \n",
    "    IDF = {}\n",
    "    \n",
    "    for word in document_count:\n",
    "        # log of total docs / number of docs word appears in\n",
    "        # use log to avoid handling small fractional numbers.\n",
    "        IDF[word] = np.log(number_docs/document_count[word])\n",
    "        \n",
    "    return IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0.6931471805599453,\n",
      " 'and': 1.3862943611198906,\n",
      " 'as': 1.3862943611198906,\n",
      " 'everywhere': 0.6931471805599453,\n",
      " 'fleece': 1.3862943611198906,\n",
      " 'go': 1.3862943611198906,\n",
      " 'had': 0.6931471805599453,\n",
      " 'lamb': 0.28768207245178085,\n",
      " 'little': 0.6931471805599453,\n",
      " 'mary': 0.0,\n",
      " 'snow': 1.3862943611198906,\n",
      " 'sure': 1.3862943611198906,\n",
      " 'that': 0.6931471805599453,\n",
      " 'the': 1.3862943611198906,\n",
      " 'to': 1.3862943611198906,\n",
      " 'was': 0.6931471805599453,\n",
      " 'went': 0.6931471805599453,\n",
      " 'white': 1.3862943611198906,\n",
      " 'whose': 1.3862943611198906}\n"
     ]
    }
   ],
   "source": [
    "# note that IDF gives a smaller weight to most common words\n",
    "# From the guy teaching this:\n",
    "# \"As expected Mary has the smallest weight of all words 0, \n",
    "# meaning that it is effectively removed from the dataset.\n",
    "# You can consider this as a way of implicitly identify and remove\n",
    "# stopwords. In case you do want to keep even the words that appear\n",
    "# in every document, you can just add a 1. to the argument of the\n",
    "# logarithm above\"\n",
    "pprint(inv_doc_freq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'mary': 0.0,\n",
       "          'had': 0.6931471805599453,\n",
       "          'a': 0.6931471805599453,\n",
       "          'little': 2.0794415416798357,\n",
       "          'lamb': 0.8630462173553426}),\n",
       " Counter({'mary': 0.0,\n",
       "          'had': 0.6931471805599453,\n",
       "          'a': 0.6931471805599453,\n",
       "          'little': 0.6931471805599453,\n",
       "          'lamb': 0.28768207245178085,\n",
       "          'whose': 1.3862943611198906,\n",
       "          'fleece': 1.3862943611198906,\n",
       "          'was': 0.6931471805599453,\n",
       "          'white': 1.3862943611198906,\n",
       "          'as': 1.3862943611198906,\n",
       "          'snow': 1.3862943611198906}),\n",
       " Counter({'and': 1.3862943611198906,\n",
       "          'everywhere': 0.6931471805599453,\n",
       "          'that': 0.6931471805599453,\n",
       "          'mary': 0.0,\n",
       "          'went': 2.0794415416798357}),\n",
       " Counter({'everywhere': 0.6931471805599453,\n",
       "          'that': 0.6931471805599453,\n",
       "          'mary': 0.0,\n",
       "          'went': 0.6931471805599453,\n",
       "          'the': 1.3862943611198906,\n",
       "          'lamb': 0.28768207245178085,\n",
       "          'was': 0.6931471805599453,\n",
       "          'sure': 1.3862943611198906,\n",
       "          'to': 1.3862943611198906,\n",
       "          'go': 1.3862943611198906})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply TF by IDF to see how relevant a word is to a doc\n",
    "\n",
    "def tf_idf(corpus_words):\n",
    "    IDF = inv_doc_freq(corpus_words)\n",
    "    \n",
    "    TFIDF = []\n",
    "    \n",
    "    for document in corpus_words:\n",
    "        TFIDF.append(Counter(document))\n",
    "    \n",
    "    for document in TFIDF:\n",
    "        for word in document:\n",
    "            document[word] = document[word]*IDF[word]\n",
    "            \n",
    "    return TFIDF\n",
    "\n",
    "tf_idf(corpus_words)\n",
    "\n",
    "# Paraphrasing: now have a vector representation of each of our documents.\n",
    "# Each vector is a unique representation of each document in the\n",
    "# corpus making it posssible to define the similarity of two documents, etc.\n",
    "\n",
    "# 'mary' has a weight of 0 as expected because it appears in every document.\n",
    "# 'little' has the strongest wait in the first document, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    STEMMING\n",
    "    \n",
    "    Finding the root, or stem, of a word to identify similar words and further reduce\n",
    "    number of words we need to consider (i.e., treat similar words as one word)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
